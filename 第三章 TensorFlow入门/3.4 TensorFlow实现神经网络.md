# 3.4 TensorFlow实现神经网络
    讲解了如何通过TensorFlow来实现神经网络
## 3.4.1 TensorFlow游乐场及神经网络简介
 - 在机器学习中，所有用于描述实体的数字的组合就是一个实体的特征向量feature vector
 - 特征向量是神经网络的输入

 - 目前主流的神经网络都是分层的结构
     - 第一层是输入层代表特征向量中每一个特征的取值。同一层的节点不会相互连接，而且每一层只和下一层连接，知道最后一层作为输出层的带计算法结果。
    - 二分类问题中，比如判断这个零件是否合格，神经网络的输出层往往只包含一个节点，而这个节点会输出一个实数值。通过这个输出值和实现设定的阈值，就可以得到最后的分类结果。一般认为当输出值离阈值越远时得到的答案越可靠。

     - 在输入层和输出层之间的神经网络叫做隐藏层，一般一个神经网络的隐藏层越多，这个神经网络越“深”。而所谓深度学习中的这个“深度”和神经网络的成熟也是密切相关的。
 - 神经网络就是通过对参数的合理设置来解决分类或者回归问题的

## 3.4.2 前向传播算法简介--本节介绍全连接网络结构的前向传播方法
 - 每个神经元的输入既可以是其他神经元的输出，也可以是整个神经网络的输入
 - 神经网络的结构指的是不同神经元的输出
 - 一个最简单的神经元结构的输出就是所有输入的加权和，而不同输入的权重就是神经元的参数
 - 神经网络的优化过程就是优化神经元中参数取值的过程

 - 全连接：相邻浪层之间任意两个节点之间都有连接

 - 计算机网络的前向传播结果需要三部分信息
     - 第一部分是神经网络的输入，输入是从实体中提取的特征向量
     - 第二部分为神经网络的连接结构。神经网络是由神经元构成的，神经网络的结构给出不同神经元之间输入输出的连接关系。神经元也可以称之为节点
     - 第三部分是每个神经元中的参数
 - 给定神经网络的输入神经网络的结构以及边上权重，就可以通过前向传播算法来计算出神经网络的输出。
 - 前向传播的算法，可以表示为矩阵乘法
  - 使用tf.matmul()实现矩阵乘法
     - a = tf.matmul(x,w1)
     - y = tf.matmul(a,w2)

## 3.4.3 神经网络参数与TensorFlow变量
 - tf.Variable(tf.random_normal([2, 3],stddev=2)) 首先调用了TensorFlow变量的声明函数tf.Variable,会产生一个2X3的矩阵，均值默认为0，标准差为2的随机数来初始化，可以通过参数mean来指定平均值，在没有指定时默认为0    P54
 - 前向传播算法
    ```
    import tensorflow as tf

    # 声明w1，w2两个变量，seed参数设定了随机种子，保证每次运行结果一样
    w1 = tf.Variable(tf.random_normal([2, 3], stddev=2, seed=1))
    w2 = tf.Variable(tf.random_normal([3, 1], stddev=2, seed=1))

    # 暂时将输入的特征向量定义为一个常亮。x是1X2的矩阵
    x = tf.constant([[0.7, 0.9]])

    # 向前传播算法获得神经网络的输出
    a = tf.matmul(x, w1)
    y = tf.matmul(a, w2)

    sess = tf.Session()
    # 不能直接sess.run(y)来获取y的取值
    # 因为w1和w2都还没有运行初始化程序。需要先初始化w1和w2两个变量
    sess.run(w1.initializer)  # 初始化w1
    sess.run(w2.initializer)  # 初始化w2

    print(sess.run(y))
    sess.close()
    ```
 - 变量定义时给出了变量初始化的方法，但这个方法并没有真正运行。计算之前，需要.initializer来给变量赋值
 - tf.global_variables_initializer()函数实现初始化所有变量的过程，会自动处理变量之间的依赖关系
    ```
    init_op = tf.global_variables_initializer()
    sess.run(init_op)
    ```
 - 在TensorFlow中变量的声明函数tf.Variable是一个运算。这个运算的输出结构就是一个张量，这个张量就是所谓的变量，所以变量只是一种特殊的张量。
 - 在一个计算图中，可以通过集合collection来管理不同类别的资源tf.add_to_collection函数将资源加入一个或多个集合中,tf.get_collection获取一个集合里面的所有资源。

 - 所以的变量都会被自动加入到GraphKeys.VARIABLE中。通过tf.global_variables()函数可以拿到当前计算图上的所有的变量。有助于持久化整个计算图的运行状态

 - 变量的类型是不可改变的
 - 维度在程序运行中是有可能改变的，但是需要通过设置参数validate_shape=False

 ## 3.4.4 通过TensorFlow训练神经网络
 - 使用监督学习的方式来更合理地设置参数取值。设置神经网络参数的过程就是神经网络的训练过程。只有经过有效训练的神经网络模型才可以真正的解决分类或者回归问题。
 - 使用监督式学习的方式设置神经网络参数需要有一个标注好的训练集参数。
 - 监督学习最重要的思想就是，在已知答案的标注数据集上，模型给出的预测结果要尽量接近真实的答案。通过调整神经网络中的参数对训练数据进行拟合，可以使得模型对位置的样本提供预测的能力。
 - 在神经网络优化算法中，最常用的方法是反向传播算法
     - 算法，实现了一个迭代的过程
     - 步骤
        - 每次迭代的开始，首先要选取一小部分训练数据，这一小部分叫做一个batch
        - 这个batch的样例会通过前向传播算法得到神经网络模型的预测结果。（因为训练数据都是由正确答案标注的，所以可以计算出当前神经网络模型的预测答案与正确答案之间的差距
        - 基于预测值和真实值之间的差距，方法传播算法相应更新神经网络参数的取值，使得在这个batch上神经网络模型的预测结构和真实答案更加接近。

     - 迭代中选取的数据不要用常量表示，否则计算图会太大，利用率低
         - 解决方法：提供了placeholder机制用于提供输入数据
         - placeholder相当于定义了一个位置，这个位置的数据在程序执行时在指定。
         - placeholderd定义时，这个位置上的数据类型是需要指定的，且其类型不可以改变。维度信息可以根据提供的数据推出，不一定要给。
     - 通过placeholder实现前向传播算法
        ```
        import tensorflow as tf

        w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))
        w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))

        # 定义placeholder作为存放数据的地方。维度不一定要定义
        # 但如果维度是确定的，那么给出维度可以降低出错的概率
        x = tf.placeholder(tf.float32, shape=(1,2), name="input")
        a = tf.matmul(x, w1)
        y = tf.matmul(a, w2)

        sess = tf.Session()
        init_op = tf.global_variables_initializer()
        sess.run(init_op)

        # 下一行将会报错
        # print(sess.run(y))

        # 得到与用常量一样的输出结果
        print(sess.run(y, feed_dict={x: [[0.7, 0.9]]}))
        ```
         - 解析
             - 替换了常量定义的输入x
             - 在计算前向传播结果时，需要提供一个feed_dict来指定x的取值。feed_dict是一个字典(map)，在字典中需要给出每个用到的placeholder的取值
             - 需要的placeholder需要有指定的取值
         - 训练神经网络时需要每次提供一个batch的训练样例，将上文输入矩阵改成n x 2的矩阵，可得到前n个样例的前向传播结果
            ```
            x = tf.placeholder(tf.float32, shape=(1,2), name="input")
            ...
            #提供三个样例数据，n为3
            print(sess.run(y, feed_dict={x: [[0.7, 0.9],[0.1, 0.4], [0.5, 0.8]]}))
            ```
 - 得到batch的前向传播结果之后，定义一个损失函数来刻画当前的预测值和真实答案之间的差距。然后提供反向传播算法来调整神经网络参数的取值使得差距可以被缩小
     - 损失函数code
        ```
        import tensorflow as tf

        # 使用sigmoid函数将y转换为0-1之间的数值。转换后y代表预测是正样本的概率，1-y代表预测是负样本的概率
        y = tf.sigmoid(y)
        # 定义损失函数来刻画预测值和真实值的差距
        cross_entropy = -tf.reduce_mean(y_*tf.log(tf.clip_by_value(y, 1e-10, 1.0))+(1-y_)*tf.log(tf.clip_by_value(1-y, 1e-10, 1.0)))
        # 定义学习率
        learning_rate = 0.001
        # 定义反向传播算法来优化神经网络中的参数
        train_step = \tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)
        ```
     - 解析
         - cross_entropy定义了真实值和预测值之间的交叉熵，这是分类问题中一个常见的损失函数
         - train_step定义了反向传播的优化方法
         - 定义了方向传播算法之后，通过运行sess.run(train_step)就可以对所有在GraphKeys.TRAINABLE_VARIABLES集合中的变量进行优化，使得在当前batch下损失函数更小

 - 3.4.5 完整神经网络样例程序
    ```

    ```
    
     - 总结出训练神经网络的过程可以分为
        1. 定义神经网络的结构和前向传播的输出结果
        2. 定义损失函数以及选择反向传播优化的算法
        3. 生成会话(tf.Session)并且在训练数据上反复运行反向传播优化算法
     - 这三个步骤是不变的


---
# 小结
 - 介绍了tensorflow最基本的三个概念——计算图(tf.Graph)，张量(tf.Tensor)和会话(tf.Session)